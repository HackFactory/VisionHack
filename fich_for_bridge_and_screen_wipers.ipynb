{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "import pandas as pd\n",
    "from av.video.stream import VideoStream\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>bridge</th>\n",
       "      <th>city_entry</th>\n",
       "      <th>city_exit</th>\n",
       "      <th>road_bump</th>\n",
       "      <th>screen_wipers</th>\n",
       "      <th>zebra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>akn.022.008.left.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>akn.031.029.left.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>akn.031.037.left.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>akn.078.031.left.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>akn.082.013.left.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name  bridge  city_entry  city_exit  road_bump  \\\n",
       "0  akn.022.008.left.avi       0           0          0          1   \n",
       "1  akn.031.029.left.avi       0           0          0          1   \n",
       "2  akn.031.037.left.avi       0           0          0          1   \n",
       "3  akn.078.031.left.avi       0           0          1          0   \n",
       "4  akn.082.013.left.avi       0           0          1          0   \n",
       "\n",
       "   screen_wipers  zebra  \n",
       "0              0      0  \n",
       "1              0      1  \n",
       "2              1      1  \n",
       "3              0      0  \n",
       "4              0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.read_csv('trainset/train.txt' , sep = ' ' , header=None, dtype=str)\n",
    "x = []\n",
    "for a in res[1]:\n",
    "    x.append(list(a))\n",
    "res.drop([1] , axis = 1 , inplace=True)\n",
    "res = pd.concat([res , pd.DataFrame(x , dtype=int)] , axis=1)\n",
    "res.columns = ['file_name' , 'bridge' , 'city_entry' , 'city_exit' , 'road_bump' , 'screen_wipers' , 'zebra']\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stats_for_file(array_file):\n",
    "    array_file = np.array(array_file)\n",
    "    \n",
    "    minim_mean = array_file.mean() - array_file.min()\n",
    "    maxim_mean = array_file.max() - array_file.mean()\n",
    "    std = array_file.std()\n",
    "    \n",
    "    diff = np.diff(array_file , n = 1)\n",
    "    min_max_1 = diff.max() - diff.min()\n",
    "    std_diff_1 = diff.std()\n",
    "    \n",
    "    diff = np.diff(array_file , n = 2)\n",
    "    min_max_2 = diff.max() - diff.min()\n",
    "    std_diff_2 = diff.std()\n",
    "    \n",
    "    diff = np.diff(array_file , n = 3)\n",
    "    min_max_3 = diff.max() - diff.min()\n",
    "    std_diff_3 = diff.std()\n",
    "    \n",
    "    return [minim_mean , maxim_mean  ,  std,  min_max_1 ,  std_diff_1 , min_max_2 ,  std_diff_2 ,min_max_3 ,  std_diff_3]\n",
    "\n",
    "def get_pixel_point(image):\n",
    "    image = image[0:100,:]\n",
    "    return image[:,:,0].mean()*0.299 + image[:,:,1].mean()*0.587 + image[:,:,2].mean()*0.114\n",
    "\n",
    "def get_array(path):\n",
    "    files = [video for video in os.listdir(path) if \".avi\" in video and \"._\" not in video]\n",
    "    data = []\n",
    "    lower_black = np.array([0, 0, 0])\n",
    "    upper_black = np.array([15, 15, 30])\n",
    "\n",
    "    kernel = np.ones((5,5),'int')\n",
    "    for file in tqdm_notebook(files):\n",
    "        array_1 = []\n",
    "        array_2 = []\n",
    "        array_3 = []\n",
    "        input_container = av.open(path + file)\n",
    "        input_packets = input_container.demux()\n",
    "        for packet in input_packets:\n",
    "            frames = packet.decode()\n",
    "            for raw_frame in frames:\n",
    "                x = raw_frame.to_rgb().to_nd_array()\n",
    "                \n",
    "                array_1.append(x[:,:,0].mean()*0.299  + x[:,:,1].mean()*0.587 + x[:,:,2].mean()*0.114)\n",
    "                array_2.append(get_pixel_point(x))\n",
    "                \n",
    "                frame_hsv = cv2.cvtColor(x, cv2.COLOR_RGB2HSV)\n",
    "                black_mask = cv2.inRange(frame_hsv, lower_black, upper_black)\n",
    "                black_mask = cv2.dilate(black_mask,kernel)\n",
    "                array_3.append((black_mask==255).sum()/black_mask.size)\n",
    "        data.append([file , array_1 , array_2 , array_3])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_fich(path):\n",
    "    fich = []\n",
    "    data =  get_array(path)\n",
    "    file = data[0]\n",
    "    for x in data[1:]:\n",
    "        fich.append(get_stats_for_file(x))\n",
    "    fich = np.hstack(fich)\n",
    "    return pd.DataFrame([data , fich] , dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fich(data):\n",
    "    fich = []\n",
    "    for x in data:\n",
    "        fich.append(np.hstack([x[0] , get_stats_for_file(x[1]) , get_stats_for_file(x[2]) ,  get_stats_for_file(x[3])]))\n",
    "    return pd.DataFrame(fich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d45f03af534bf7887403860a9e7023"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream #0: not enough frames to estimate rate; consider increasing probesize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415edc259d4d4bea8b23aa48d6531989"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train = get_array('trainset/')\n",
    "valid = get_array('validationset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fich = get_fich(train)\n",
    "valid_fich = get_fich(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_right_answer(data , res , col):\n",
    "    r = []\n",
    "    for i in range(data.shape[0]):\n",
    "        r.append(int(res[res.file_name == data.loc[i][0]][col]))\n",
    "    return np.array(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.990938563352 0.0104668134402\n",
      "(53, 2)\n",
      "0.965714285714 0.0685714285714\n",
      "(31, 2)\n"
     ]
    }
   ],
   "source": [
    "path_valid = 'validationset/'\n",
    "files_valid = [video for video in os.listdir(path_valid) if \".avi\" in video and \"._\" not in video]\n",
    "sub = pd.DataFrame(files_valid)\n",
    "\n",
    "dict_answ = {\n",
    "    0: '000000',\n",
    "    1: '100000',\n",
    "    2: '010000',\n",
    "    3: '001000',\n",
    "    4: '000100',\n",
    "    5: '000010',\n",
    "    6: '000001'\n",
    "}\n",
    "\n",
    "for i , porog  in zip([1 , 5] , [0.5,0.5]):\n",
    "    right_answ = get_right_answer(train_fich , res , res.columns[i])\n",
    "    model = CatBoostClassifier(random_seed=0)\n",
    "    a = cross_val_score(model , train_fich.drop([0] , axis=1).values, right_answ , cv = 5 , scoring='roc_auc')\n",
    "    print (a.mean() , a.std())\n",
    "    model.fit(train_fich.drop([0] , axis=1).values, right_answ)\n",
    "    sub['res'] = model.predict_proba(valid_fich.drop([0] , axis=1).values)[:,1]\n",
    "    sub['res'] = sub['res'].apply(lambda x: dict_answ[i] if x >= porog  else dict_answ[0])\n",
    "    print (sub[sub.res == dict_answ[i]].shape)\n",
    "    sub.to_csv(str(i) + '.txt' , sep = ' ' , header=None , index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fich.to_csv('train.csv')\n",
    "valid_fich.to_csv('valid.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
